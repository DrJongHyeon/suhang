import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import requests
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import MinMaxScaler
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from io import BytesIO

# ---------------------
# ê¸°ë³¸ ì„¤ì • ë° ì œëª©
# ---------------------
st.set_page_config(page_title="ì• ë‹ˆ ì¶”ì²œ ì›¹ì•±", layout="wide")
st.title("ğŸŒ ì• ë‹ˆë©”ì´ì…˜ ì¶”ì²œ ì›¹ì•±")
st.markdown(
    "[ğŸ“‚ ë°ì´í„° ì¶œì²˜ (Kaggle)](https://www.kaggle.com/datasets/CooperUnion/anime-recommendations-database?select=anime.csv)",
    unsafe_allow_html=True,
)

# ---------------------
# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬
# ---------------------
@st.cache_data
def load_data():
    df = pd.read_csv("anime.csv")
    df = df.dropna(subset=["name"])  # ì´ë¦„ ì—†ëŠ” í–‰ ì œê±°
    df["genre"] = df["genre"].fillna("").str.lower()
    df["type"] = df["type"].fillna("Unknown")

    # Gintama í†µí•©
    gintama_mask = df["name"].str.contains("Gintama", case=False, na=False)
    if gintama_mask.sum() > 1:
        gintama_entry = df[gintama_mask].sort_values("members", ascending=False).iloc[0]
        df = df[~gintama_mask]
        df = pd.concat([df, pd.DataFrame([gintama_entry])], ignore_index=True)

    return df

anime_df = load_data()

# ---------------------
# ì‚¬ìš©ì ì…ë ¥: ì¥ë¥´, í˜•ì‹, í‰ì /ì¸ê¸°ë„ ë²”ìœ„
# ---------------------
with st.sidebar:
    st.header("ğŸ” í•„í„° ì˜µì…˜")

    all_genres = sorted(set(g for genre in anime_df["genre"].dropna() for g in genre.split(", ")))
    selected_genres = st.multiselect("ì¥ë¥´ ì„ íƒ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)", options=all_genres)

    all_types = sorted(anime_df["type"].dropna().unique())
    selected_types = st.multiselect("í˜•ì‹ ì„ íƒ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)", options=all_types)

    min_score, max_score = st.slider("í‰ì  ë²”ìœ„", 0.0, 10.0, (5.0, 10.0), step=0.1)
    min_members, max_members = st.slider("ì¸ê¸°ë„ ë²”ìœ„ (members ìˆ˜)", 0, int(anime_df["members"].max()), (1000, 500000))

# ---------------------
# í•„í„°ë§ ì ìš©
# ---------------------
filtered_df = anime_df.copy()

if selected_genres:
    filtered_df = filtered_df[filtered_df["genre"].apply(lambda g: any(gen in g for gen in selected_genres))]

if selected_types:
    filtered_df = filtered_df[filtered_df["type"].isin(selected_types)]

filtered_df = filtered_df[
    (filtered_df["rating"] >= min_score) &
    (filtered_df["members"] >= min_members) &
    (filtered_df["members"] <= max_members)
]

# ---------------------
# ì‹œê°í™”: í‰ì  & ì¸ê¸°ë„ (ê°€ë¡œ ë§‰ëŒ€)
# ---------------------
st.subheader("ğŸ“Š í‰ì  ê¸°ì¤€ ìƒìœ„ ì• ë‹ˆë©”ì´ì…˜")
top_rating = filtered_df.sort_values("rating", ascending=False).head(10)
fig_rating = px.bar(top_rating, x="rating", y="name", orientation="h", color="type", title="Top 10 by Rating")
st.plotly_chart(fig_rating, use_container_width=True)

st.subheader("ğŸ“ˆ ì¸ê¸°ë„ ê¸°ì¤€ ìƒìœ„ ì• ë‹ˆë©”ì´ì…˜")
top_members = filtered_df.sort_values("members", ascending=False).head(10)
fig_members = px.bar(top_members, x="members", y="name", orientation="h", color="type", title="Top 10 by Popularity")
st.plotly_chart(fig_members, use_container_width=True)

# ---------------------
# ì¶”ì²œ ëª¨ë“œ ì„ íƒ
# ---------------------
st.header("ğŸ¯ ì• ë‹ˆë©”ì´ì…˜ ì¶”ì²œ")
recommend_mode = st.radio("ì¶”ì²œ ë°©ì‹ ì„ íƒ", ["ì„ íƒí•œ í•„í„° ê¸°ë°˜", "ì…ë ¥í•œ ì• ë‹ˆ ê¸°ë°˜"])

# ---------------------
# ì´ë¯¸ì§€ ì œì™¸ ì¥ë¥´
# ---------------------
EXCLUDED_GENRES_FOR_IMAGE = {"hentai", "ecchi", "horror", "yaoi"}

def get_anime_image(title, genre=""):
    if any(bad in genre.lower() for bad in EXCLUDED_GENRES_FOR_IMAGE):
        return None

    try:
        url = f"https://api.jikan.moe/v4/anime?q={title}&limit=1"
        resp = requests.get(url)
        data = resp.json()
        return data["data"][0]["images"]["jpg"]["image_url"]
    except:
        return None

def generate_wordcloud(text):
    if not text:
        return None
    wc = WordCloud(width=600, height=400, background_color="white").generate(text)
    buf = BytesIO()
    plt.figure(figsize=(6, 4))
    plt.imshow(wc, interpolation="bilinear")
    plt.axis("off")
    plt.tight_layout()
    plt.savefig(buf, format="png")
    plt.close()
    return buf

# ---------------------
# 1. í•„í„° ê¸°ë°˜ ì¶”ì²œ
# ---------------------
if recommend_mode == "ì„ íƒí•œ í•„í„° ê¸°ë°˜":
    st.subheader("ğŸ” í•„í„° ê¸°ë°˜ ì¶”ì²œ ê²°ê³¼")
    if filtered_df.empty:
        st.warning("ì¡°ê±´ì— ë§ëŠ” ì• ë‹ˆë©”ì´ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for _, row in filtered_df.sort_values("rating", ascending=False).head(10).iterrows():
            col1, col2 = st.columns([1, 2])
            with col1:
                img_url = get_anime_image(row["name"], row["genre"])
                if img_url:
                    st.image(img_url, caption=row["name"])
                else:
                    st.image("https://via.placeholder.com/150?text=No+Image", caption=row["name"])
            with col2:
                if synopsis and not genre_set.intersection(EXCLUDED_IMAGE_GENRES):
                    wc_buf = generate_wordcloud(synopsis)
                    st.image(wc_buf, caption="ğŸ“š ì›Œë“œí´ë¼ìš°ë“œ (ì‹œë†‰ì‹œìŠ¤ ê¸°ë°˜)", use_container_width=True)
                else:
                    st.write("ì›Œë“œí´ë¼ìš°ë“œ ì—†ìŒ")


# ---------------------
# 2. ì…ë ¥ ê¸°ë°˜ ì¶”ì²œ (Content-based)
# ---------------------
else:
    st.subheader("ğŸ§  ì…ë ¥í•œ ì• ë‹ˆì™€ ìœ ì‚¬í•œ ì• ë‹ˆ ì¶”ì²œ")

    anime_options = anime_df["name"].sort_values().unique().tolist()
    selected_titles = st.multiselect("ê¸°ì¤€ì´ ë  ì• ë‹ˆë©”ì´ì…˜ ì„ íƒ", anime_options)

    def recommend_by_content(df, selected_titles):
        df = df.dropna(subset=["genre"])
        df = df.reset_index(drop=True)

        tfidf = TfidfVectorizer(stop_words="english")
        tfidf_matrix = tfidf.fit_transform(df["genre"])

        sim_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)
        indices = pd.Series(df.index, index=df["name"]).drop_duplicates()

        selected_indices = indices[selected_titles].values
        sim_scores = sim_matrix[selected_indices].mean(axis=0)

        df["similarity"] = sim_scores
        recommended = df[~df["name"].isin(selected_titles)]
        return recommended.sort_values("similarity", ascending=False).head(10)

    if selected_titles:
        results = recommend_by_content(anime_df, selected_titles)
        for _, row in results.iterrows():
            col1, col2 = st.columns([1, 2])
            with col1:
                img_url = get_anime_image(row["name"], row["genre"])
                if img_url:
                    st.image(img_url, caption=row["name"])
                else:
                    st.image("https://via.placeholder.com/150?text=No+Image", caption=row["name"])
            with col2:
                st.markdown(f"**{row['name']}**  \nâ­ í‰ì : {row['rating']}  \nğŸ‘¥ ì¸ê¸°ë„: {row['members']}  \nğŸï¸ í˜•ì‹: {row['type']}")
                wc_buf = generate_wordcloud(row["genre"])
                if wc_buf:
                    st.image(wc_buf, caption="ğŸ“Œ ì¥ë¥´ WordCloud", use_container_width=True)
    else:
        st.info("ì™¼ìª½ì—ì„œ ê¸°ì¤€ ì• ë‹ˆë©”ì´ì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
